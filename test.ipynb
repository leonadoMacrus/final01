{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Thực hiện nghiên cứu mô phỏng và in kết quả\u001b[39;00m\n\u001b[1;32m     57\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 58\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m alpha_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     60\u001b[0m n_pcs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m]\n",
      "Cell \u001b[0;32mIn[23], line 45\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data\u001b[39m(file_path):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Đọc dữ liệu từ tệp CSV\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Loại bỏ các giá trị thiếu\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     df\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.csv'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from compositions import alfa\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Hàm biến đổi ilr\n",
    "def ilr_transform(data):\n",
    "    ilr_data = np.zeros_like(data)\n",
    "    for i in range(1, data.shape[1]):\n",
    "        ilr_data[:, i - 1] = np.sqrt(i / (i + 1)) * np.log(data[:, i] / data[:, i - 1])\n",
    "    return ilr_data\n",
    "\n",
    "# Hàm thực hiện hồi quy tuyến tính với ILR\n",
    "def ilr_linear_regression(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    return rmse\n",
    "\n",
    "# Thực hiện nghiên cứu mô phỏng\n",
    "def simulation_study(data, alpha_values, n_pcs):\n",
    "    results = []\n",
    "    for alpha in alpha_values:\n",
    "        for n_pc in n_pcs:\n",
    "            # Biến đổi ILR cho dữ liệu\n",
    "            X = ilr_transform(data)\n",
    "            # Áp dụng phương pháp Alpha-PCR với ILR\n",
    "            xa = alfa(X, alpha)[\"aff\"]\n",
    "            pca = PCA(n_components=n_pc)\n",
    "            sc = pca.fit_transform(xa)\n",
    "            y = data[:, 0]  # Giả sử cột đầu tiên là biến phụ thuộc\n",
    "            X_train, X_test, y_train, y_test = train_test_split(sc, y, test_size=0.2, random_state=42)\n",
    "            rmse = ilr_linear_regression(X_train, X_test, y_train, y_test)\n",
    "            results.append((alpha, n_pc, rmse))\n",
    "    return results\n",
    "\n",
    "# Đọc dữ liệu từ tệp CSV và tiền xử lý\n",
    "def preprocess_data(file_path):\n",
    "    # Đọc dữ liệu từ tệp CSV\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Loại bỏ các giá trị thiếu\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Chuẩn hóa dữ liệu\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "    return scaled_data\n",
    "\n",
    "# Thực hiện nghiên cứu mô phỏng và in kết quả\n",
    "file_path = \"data.csv\"\n",
    "data = preprocess_data(file_path)\n",
    "alpha_values = np.linspace(0.1, 1, 10)\n",
    "n_pcs = [1, 2, 3, 4, 5, 6, 7]\n",
    "results = simulation_study(data, alpha_values, n_pcs)\n",
    "for result in results:\n",
    "    print(\"Alpha:\", result[0], \"- Number of PCs:\", result[1], \"- RMSE:\", result[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_alfapcr(y, x, covar=None, a=None, k=None, xnew=None, B=1, ncores=1, tol=1e-07, maxiters=50):\n",
    "    # Tính toán clr của dữ liệu đầu vào x\n",
    "    z = clr(x)\n",
    "    n, p = z.shape\n",
    "    # Kiểm tra nếu số lượng components vượt quá số lượng features\n",
    "    if k is not None and k > p:\n",
    "        k = p\n",
    "    # Sử dụng PCA để tính toán các thành phần chính và giá trị eigen tương ứng\n",
    "    eig = PCA(n_components=k).fit(z)\n",
    "    values = eig.explained_variance_\n",
    "    # Tính tổng tích lũy của các giá trị eigen\n",
    "    per = np.cumsum(values / np.sum(values))\n",
    "    # Lấy các thành phần của PCA\n",
    "    vec = eig.components_.T\n",
    "    # Biến đổi dữ liệu ban đầu thành không gian của các thành phần chính\n",
    "    sc = eig.transform(z)\n",
    "    # Nếu có covariates, nối chúng vào sc\n",
    "    if covar is not None:\n",
    "        sc = np.hstack((sc, covar))\n",
    "    # Nếu có dữ liệu mới đầu vào, tính toán clr cho nó\n",
    "    if xnew is not None:\n",
    "        xnew = clr(xnew)\n",
    "        xnew = np.hstack((np.dot(xnew, vec), covar))\n",
    "    # Áp dụng hàm kl_compreg từ gói Compositional cho dữ liệu đã được biến đổi\n",
    "    return kl_compreg(y, sc, xnew=xnew, B=B, ncores=ncores, tol=tol, maxiters=maxiters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_alfapcr_tune(y, x, covar=None, M=10, maxk=50, a=np.arange(-1, 1.1, 0.1), mat=None, graph=False, tol=1e-07, maxiters=50):\n",
    "    n, p = x.shape\n",
    "    # Kiểm tra nếu giá trị nhỏ nhất trong dữ liệu là 0, chỉ sử dụng các giá trị alpha dương\n",
    "    if np.min(x.values) == 0:\n",
    "        a = a[a > 0]\n",
    "    # Đảm bảo không quá số lượng features khi thiết lập maxk\n",
    "    if maxk > p:\n",
    "        maxk = p\n",
    "    if covar is not None:\n",
    "        covar = np.array(covar)\n",
    "    # Tạo ma trận mat để chia dữ liệu thành các tập con\n",
    "    if mat is None:\n",
    "        nu = np.random.choice(np.arange(n), size=min(n, round(n / M) * M), replace=False)\n",
    "        mat = nu.reshape((-1, M))\n",
    "    mspe = []\n",
    "    # Lặp qua các giá trị alpha\n",
    "    for alpha in a:\n",
    "        xa = clr(x.values)\n",
    "        msp = np.zeros((M, maxk))\n",
    "        # Lặp qua từng tập con\n",
    "        for vim in range(M):\n",
    "            # Chia dữ liệu thành tập train và tập test\n",
    "            ytest = y.iloc[mat[:, vim], :]\n",
    "            ytrain = y.drop(index=y.index[mat[:, vim]])\n",
    "            xtrain = xa[~np.isin(np.arange(n), mat[:, vim]), :]\n",
    "            xtest = xa[np.isin(np.arange(n), mat[:, vim]), :]\n",
    "            # Tính tổng entropy của dữ liệu test\n",
    "            com = np.sum(ytest * np.log(ytest))\n",
    "            # Áp dụng PCA cho tập train\n",
    "            mod = PCA(n_components=maxk).fit(xtrain)\n",
    "            vec = mod.components_.T\n",
    "            za = mod.transform(xtrain)\n",
    "            zanew = np.dot(xtest, vec)\n",
    "            # Lặp qua từng số lượng components\n",
    "            for j in range(maxk):\n",
    "                if covar is not None:\n",
    "                    # Nếu có covariates, nối chúng vào z\n",
    "                    z = np.hstack((za[:, :j+1], covar[~np.isin(np.arange(n), mat[:, vim])]))\n",
    "                    znew = np.hstack((zanew[:, :j+1], covar[np.isin(np.arange(n), mat[:, vim])]))\n",
    "                else:\n",
    "                    z = za[:, :j+1]\n",
    "                    znew = zanew[:, :j+1]\n",
    "                # Áp dụng hàm kl_compreg từ gói Compositional cho dữ liệu đã được biến đổi\n",
    "                est = kl_compreg(ytrain.values, z, xnew=znew, tol=1e-07, maxiters=50)['est']\n",
    "                res = np.sum(ytest * np.log(est))\n",
    "                msp[vim, j] = com - res * np.isfinite(res)\n",
    "        mspe.append(msp)\n",
    "# Tính toán hiệu suất trung bình của từng alpha và số lượng PCs\n",
    "    performance = np.mean(mspe, axis=1)\n",
    "    performance = np.vstack(performance)\n",
    "    # Xác định alpha và số lượng PCs tốt nhất dựa trên hiệu suất\n",
    "    best_alpha_idx, best_k_idx = np.unravel_index(np.argmin(performance, axis=None), performance.shape)\n",
    "    best_alpha = a[best_alpha_idx]\n",
    "    best_k = best_k_idx + 1  # Vì chỉ số bắt đầu từ 0\n",
    "    best_performance = np.min(performance)\n",
    "    # Trả về kết quả tinh chỉnh và hiệu suất\n",
    "    result = {'mspe': mspe, 'performance': performance, 'best_alpha': best_alpha, 'best_k': best_k, 'best_performance': best_performance}\n",
    "    if graph:\n",
    "        # Vẽ biểu đồ contour cho hiệu suất\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.contourf(a, np.arange(1, maxk + 1), performance.T)\n",
    "        plt.colorbar(label='Average KL Divergence')\n",
    "        plt.xlabel('Alpha values')\n",
    "        plt.ylabel('Number of PCs')\n",
    "        plt.title('Performance of KL-ALFAPCR Tuning')\n",
    "        plt.show()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CensusTract</th>\n",
       "      <th>State</th>\n",
       "      <th>County</th>\n",
       "      <th>TotalPop</th>\n",
       "      <th>Men</th>\n",
       "      <th>Women</th>\n",
       "      <th>Hispanic</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Native</th>\n",
       "      <th>...</th>\n",
       "      <th>Walk</th>\n",
       "      <th>OtherTransp</th>\n",
       "      <th>WorkAtHome</th>\n",
       "      <th>MeanCommute</th>\n",
       "      <th>Employed</th>\n",
       "      <th>PrivateWork</th>\n",
       "      <th>PublicWork</th>\n",
       "      <th>SelfEmployed</th>\n",
       "      <th>FamilyWork</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001020100</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>1948</td>\n",
       "      <td>940</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.9</td>\n",
       "      <td>87.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>943</td>\n",
       "      <td>77.1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001020200</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>2156</td>\n",
       "      <td>1059</td>\n",
       "      <td>1097</td>\n",
       "      <td>0.8</td>\n",
       "      <td>40.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>753</td>\n",
       "      <td>77.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001020300</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>2968</td>\n",
       "      <td>1364</td>\n",
       "      <td>1604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1373</td>\n",
       "      <td>64.1</td>\n",
       "      <td>23.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001020400</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>4423</td>\n",
       "      <td>2172</td>\n",
       "      <td>2251</td>\n",
       "      <td>10.5</td>\n",
       "      <td>82.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>1782</td>\n",
       "      <td>75.7</td>\n",
       "      <td>21.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001020500</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>10763</td>\n",
       "      <td>4922</td>\n",
       "      <td>5841</td>\n",
       "      <td>0.7</td>\n",
       "      <td>68.5</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>24.8</td>\n",
       "      <td>5037</td>\n",
       "      <td>67.1</td>\n",
       "      <td>27.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CensusTract    State   County  TotalPop   Men  Women  Hispanic  White  \\\n",
       "0   1001020100  Alabama  Autauga      1948   940   1008       0.9   87.4   \n",
       "1   1001020200  Alabama  Autauga      2156  1059   1097       0.8   40.4   \n",
       "2   1001020300  Alabama  Autauga      2968  1364   1604       0.0   74.5   \n",
       "3   1001020400  Alabama  Autauga      4423  2172   2251      10.5   82.8   \n",
       "4   1001020500  Alabama  Autauga     10763  4922   5841       0.7   68.5   \n",
       "\n",
       "   Black  Native  ...  Walk  OtherTransp  WorkAtHome  MeanCommute  Employed  \\\n",
       "0    7.7     0.3  ...   0.5          2.3         2.1         25.0       943   \n",
       "1   53.3     0.0  ...   0.0          0.7         0.0         23.4       753   \n",
       "2   18.6     0.5  ...   0.0          0.0         2.5         19.6      1373   \n",
       "3    3.7     1.6  ...   0.0          2.6         1.6         25.3      1782   \n",
       "4   24.8     0.0  ...   0.0          0.6         0.9         24.8      5037   \n",
       "\n",
       "   PrivateWork  PublicWork  SelfEmployed  FamilyWork  Unemployment  \n",
       "0         77.1        18.3           4.6         0.0           5.4  \n",
       "1         77.0        16.9           6.1         0.0          13.3  \n",
       "2         64.1        23.6          12.3         0.0           6.2  \n",
       "3         75.7        21.2           3.1         0.0          10.8  \n",
       "4         67.1        27.6           5.3         0.0           4.2  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pd.read_csv(\"./acs2015_census.csv\"))\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Professional</th>\n",
       "      <th>Service</th>\n",
       "      <th>Office</th>\n",
       "      <th>Construction</th>\n",
       "      <th>Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>11.9</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.3</td>\n",
       "      <td>24.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.4</td>\n",
       "      <td>24.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>9.2</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Professional  Service  Office  Construction  Production\n",
       "0          34.7     17.0    21.3          11.9        15.2\n",
       "1          22.3     24.7    21.5           9.4        22.0\n",
       "2          31.4     24.9    22.1           9.2        12.4\n",
       "3          27.0     20.8    27.0           8.7        16.4\n",
       "4          49.6     14.2    18.2           2.1        15.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Xác định các biến thành phần độc lập và biến giải thích\n",
    "compositional_cols = ['Professional','Service','Office','Construction','Production']\n",
    "\n",
    "#data = \n",
    "var_target = df['Income']\n",
    "#family = family[(family != 0).all(axis=1)]\n",
    "\n",
    "# chuyển dữ liệu thành phần\n",
    "compositional_data = df[compositional_cols]\n",
    "#compositional_data = compositional_data.div(compositional_data.sum(axis=1), axis=0)\n",
    "compositional_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\u001b[39;00m\n\u001b[1;32m     13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(compositional_data, var_target, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mkl_alfapcr_tune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompositional_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_target\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m, in \u001b[0;36mkl_alfapcr_tune\u001b[0;34m(y, x, covar, M, maxk, a, mat, graph, tol, maxiters)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkl_alfapcr_tune\u001b[39m(y, x, covar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, maxk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, a\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1.1\u001b[39m, \u001b[38;5;241m0.1\u001b[39m), mat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-07\u001b[39m, maxiters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     n, p \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Kiểm tra nếu giá trị nhỏ nhất trong dữ liệu là 0, chỉ sử dụng các giá trị alpha dương\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(x\u001b[38;5;241m.\u001b[39mvalues) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# Thay thế các giá trị bằng 0 bằng một epsilon nhỏ\n",
    "epsilon = 1e-9\n",
    "compositional_data = compositional_data.replace(0, epsilon)\n",
    "\n",
    "# Chuyển đổi dữ liệu thành phần bằng centered log-ratio (CLR)\n",
    "clr_compositional_data = clr(compositional_data)\n",
    "\n",
    "# Chuyển dữ liệu CLR về dạng DataFrame để tiện sử dụng\n",
    "#clr_compositional_data = pd.DataFrame(clr_compositional_data, columns=compositional_cols)\n",
    "clr_compositional_data = pd.DataFrame(clr_compositional_data)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(compositional_data, var_target, test_size=0.2, random_state=42)\n",
    "\n",
    "kl_alfapcr_tune(compositional_data, var_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
